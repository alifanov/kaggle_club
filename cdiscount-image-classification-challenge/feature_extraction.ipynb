{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/alifanov/PycharmProjects/kaggle_club/venv/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import itertools\n",
    "import io\n",
    "import time\n",
    "import bson\n",
    "import threading\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "import keras\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouper(n, iterable):\n",
    "    '''\n",
    "    Given an iterable, it'll return size n chunks per iteration.\n",
    "    Handles the last chunk too.\n",
    "    '''\n",
    "    it = iter(iterable)\n",
    "    while True:\n",
    "        chunk = tuple(itertools.islice(it, n))\n",
    "        if not chunk:\n",
    "            return\n",
    "        yield chunk\n",
    "        \n",
    "class threadsafe_iter:\n",
    "    \"\"\"\n",
    "    Takes an iterator/generator and makes it thread-safe by\n",
    "    serializing call to the `next` method of given iterator/generator.\n",
    "    \"\"\"\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            return self.it.__next__()\n",
    "\n",
    "def threadsafe_generator(f):\n",
    "    \"\"\"\n",
    "    A decorator that takes a generator function and makes it thread-safe.\n",
    "    \"\"\"\n",
    "    def g(*a, **kw):\n",
    "        return threadsafe_iter(f(*a, **kw))\n",
    "    return g\n",
    "\n",
    "@threadsafe_generator\n",
    "def get_features_label(documents, batch_size=32, return_labels=True):\n",
    "    '''\n",
    "    Given a document return X, y\n",
    "    \n",
    "    X is scaled to [0, 1] and consists of all images contained in document.\n",
    "    y is given an integer encoding.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    for batch in grouper(batch_size, documents): \n",
    "        images = []\n",
    "        labels = []\n",
    "\n",
    "        for document in batch:\n",
    "            category = document.get('category_id', '')\n",
    "            img = document.get('imgs')[0]\n",
    "            data = io.BytesIO(img.get('picture', None))\n",
    "            im = imread(data)\n",
    "\n",
    "            if category:    \n",
    "                label = labelencoder.transform([category])\n",
    "            else:\n",
    "                label = None\n",
    "\n",
    "            im = im.astype('float32') / 255.0\n",
    "\n",
    "            images.append(im)\n",
    "            labels.append(label)\n",
    "\n",
    "        if return_labels:\n",
    "            yield np.array(images), np.array(labels)\n",
    "        else:\n",
    "            yield np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('labelencoder.pkl'):\n",
    "    with open('labelencoder.pkl', 'rb') as f:\n",
    "        labelencoder = pickle.load(f)\n",
    "    categories = pd.read_csv('categories.csv')\n",
    "    \n",
    "else:\n",
    "    # Get the category ID for each document in the training set.\n",
    "    documents = bson.decode_file_iter(open('train_example.bson', 'rb'))\n",
    "    categories = [(d['_id'], d['category_id']) for d in documents]\n",
    "    categories = pd.DataFrame(categories, columns=['id', 'cat'])\n",
    "\n",
    "    # Create a label encoder for all the labels found\n",
    "    labelencoder = LabelEncoder()\n",
    "    labelencoder.fit(categories.cat.unique().ravel())\n",
    "    \n",
    "    with open('labelencoder.pkl', 'wb') as f:\n",
    "        pickle.dump(labelencoder, f)\n",
    "        \n",
    "    categories.to_csv('categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 180, 180, 3)\n",
      "(32, 180, 180, 3)\n",
      "(18, 180, 180, 3)\n"
     ]
    }
   ],
   "source": [
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "generator = get_features_label(bson.decode_file_iter(open('train_example.bson', 'rb')), return_labels=False)\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for i, batch in enumerate(generator):\n",
    "    print(batch.shape)\n",
    "    output = model.predict(batch)\n",
    "    predictions.append(output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 5, 5, 512)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
